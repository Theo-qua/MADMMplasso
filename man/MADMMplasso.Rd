% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MADAMM11.R
\name{MADMMplasso}
\alias{MADMMplasso}
\title{Fit a multi-response pliable lasso model over a path of regularization values}
\usage{
MADMMplasso(
  X,
  Z,
  y,
  alpha,
  my_lambda = NULL,
  lambda_min = 0.001,
  max_it = 50000,
  e.abs = 0.001,
  e.rel = 0.001,
  maxgrid,
  nlambda,
  rho = 5,
  my_print = F,
  alph = 1.8,
  tree,
  cv = F,
  parallel = T,
  pal = 0,
  gg = 0.05,
  tol = 1e-04,
  cl = 4
)
}
\arguments{
\item{X}{N by p matrix of predictors}

\item{Z}{N by K matrix of modifying variables. The elements of Z  may represent quantitative or categorical variables, or a mixture of the two.
Categorical varables should be coded by 0-1 dummy variables: for a k-level variable, one can use either k or k-1  dummy variables.}

\item{y}{N by D matrix  of responses. The X and Z variables are centered in the function. We recommmend that X and Z also be standardized before the call}

\item{alpha}{mixing parameter- default 0.5
#' @param max_it maximum number of iterations in the ADMM algorithm for one lambda. Default 50000}

\item{e.abs}{absolute error for the admm}

\item{e.rel}{relative error for the admm}

\item{maxgrid}{similar to nlambda}

\item{nlambda}{number of lambda values desired (default 50).}

\item{rho}{the Lagrange variable for the ADMM}

\item{gg}{penalty term for the tree structure}

\item{lambda.min.ratio}{the smallest value for lambda , as a fraction of
lambda.max, the (data derived) entry value (i.e. the smallest value for which all coefficients are zero).
Default is 0.001 if n>p, and 0.01 if n< p.}
}
\description{
Fit a multi-response pliable lasso model over a path of regularization values
}
\examples{
Train the model
generate some data
set.seed(1235)
N = 100 ; p =500;nz=4; K=nz
X <- matrix(rnorm(n = N * p), nrow = N, ncol = p)
mx=colMeans(X)
sx=sqrt(apply(X,2,var))
X=scale(X,mx,sx)
X=matrix(as.numeric(X),N,p)
Z =matrix(rnorm(N*nz),N,nz)
mz=colMeans(Z)
sz=sqrt(apply(Z,2,var))
Z=scale(Z,mz,sz)
beta_1 <- rep(x = 0, times = p); beta_2<-rep(x = 0, times = p);beta_3<-rep(x = 0, times = p);beta_4<-rep(x = 0, times = p);beta_5<-rep(x = 0, times = p);beta_6<-rep(x = 0, times = p)


beta_1[1:5] <- c(2, 2, 2, 2,2); beta_2[1:5]<-c(2, 2, 2, 2,2); beta_3[6:10]<-c(2, 2, 2, -2,-2); beta_4[6:10] <- c(2, 2, 2, -2,-2); beta_5[11:15] <- c(-2,  -2,-2, -2,-2);beta_6[11:15] <- c(-2, -2, -2, -2,-2)

Beta<-cbind(beta_1,beta_2,beta_3,beta_4,beta_5,beta_6)
colnames(Beta)<-c(1:6)


theta<-array(0,c(p,K,6))
theta[1,1,1]<-2;theta[3,2,1]<-2;theta[4,3,1]<- -2;theta[5,4,1]<- -2
theta[1,1,2]<-2;theta[3,2,2]<-2;theta[4,3,2]<- -2;theta[5,4,2]<- -2
theta[6,1,3]<-2;theta[8,2,3]<-2;theta[9,3,3]<- -2;theta[10,4,3]<- -2
theta[6,1,4]<-2;theta[8,2,4]<-2;theta[9,3,4]<- -2;theta[10,4,4]<- -2
theta[11,1,5]<-2;theta[13,2,5]<-2;theta[14,3,5]<- -2;theta[15,4,5]<- -2
theta[11,1,6]<-2;theta[13,2,6]<-2;theta[14,3,6]<- -2;theta[15,4,6]<- -2

library(MASS)
pliable = matrix(0,N,6)
for (e in 1:6) {
pliable[,e]<-	compute_pliable(X, Z, theta[,,e])
}

esd<-diag(6)
e<-mvrnorm(N,mu=rep(0,6),Sigma=esd)
y_train<-X\%*\%Beta+pliable+e
y=y_train
#colnames(y)<-c(1:6)
colnames(y)<- c( paste("y",1:(ncol(y)),sep = "") )
TT=tree.parms(y)
plot(TT$h_clust)
gg1<-c(.5,0.0001)
cl=detectCores()
nlambda = 50;e.abs=1E-3;e.rel=1E-3;alpha=.5
 fit<-MADMMplasso(X,Z,y,alpha=alpha,my_lambda=NULL,lambda_min=0.01,max_it=5000,e.abs=e.abs,e.rel=e.rel,maxgrid=50,nlambda = nlambda, rho=5,tree = TT,my_print = F,alph=1,parallel =F,pal=1,gg=gg1,tol=1E-3,cl=cl-2 )
 plot(fit) 
}
